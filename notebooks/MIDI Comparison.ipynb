{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "class MidiEncodingTransformer(object):\n",
    "    \"\"\"\n",
    "    An object to facilitate transferring encoding schemes.\n",
    "    For a detailed overview of the different encoding schemes, please see:\n",
    "    \n",
    "    Dannenberg, Roger B., et al.\n",
    "    \"A comparative evaluation of search techniques for query‐by‐humming using the MUSART testbed.\"\n",
    "    Journal of the American Society for Information Science and Technology 58.5 (2007): 687-701.\n",
    "    \n",
    "    Link to pdf:\n",
    "    https://pdfs.semanticscholar.org/fb78/28edee96c2ca39cca045aeebc77c1e7aaf0a.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    supported_encodings = set(['logIOIr', 'IOIr', 'IOI'])\n",
    "    def __init__(self, encoding='logIOIr', n_bins=5, saturation_point = 2):\n",
    "        \"\"\"\n",
    "        n_bins - number of bins that we will be using to represent the data\n",
    "        saturation_point - the maximum value allowed for the timing encoding format\n",
    "            (e.g. if saturation_point = 2 then an IOIr value of 3 will be rounded down to 2)\n",
    "        \"\"\"\n",
    "        if encoding not in MidiEncodingTransformer.supported_encodings:\n",
    "            raise ValueError('%s is not a supported encoding' % encoding)        \n",
    "        \n",
    "        self.encoding = encoding\n",
    "        self.n_bins = n_bins\n",
    "        \n",
    "        #we will be using 's' to refer to the saturation point as well when creating the bins\n",
    "        self.saturation_point = s = saturation_point\n",
    "        \n",
    "    \n",
    "        #create the bins for the encoding\n",
    "        if encoding == 'logIOIr':\n",
    "            self.bins = np.linspace(-s, s, n_bins)\n",
    "        else:\n",
    "            self.bins = np.linspace(0, s, n_bins)\n",
    "                \n",
    "    def transform(self, note_events):\n",
    "        \"\"\"\n",
    "        Returns the desired encoding of a midi object\n",
    "        \n",
    "        INPUT:\n",
    "        note_events - [(note, t_on, t_off) for note in notes]\n",
    "        \"\"\"\n",
    "        \n",
    "        pitches, onsets, offsets = zip(*note_events)\n",
    "        note_times = (onsets, offsets)\n",
    "        \n",
    "        rel_pitches = MidiEncodingTransformer.get_relative_pitches(pitches)\n",
    "        \n",
    "        IOI = MidiEncodingTransformer.get_IOI(note_times)\n",
    "                \n",
    "        if self.encoding == 'IOI':\n",
    "            #IOI has one more value than IOIr and logIOIr, so we add a rel_pitch of 0 at the end\n",
    "            #this will never be used by my team, but is fine for consistency\n",
    "            rel_pitches.append(0)\n",
    "            return zip(rel_pitches, self.bin_events(IOI))\n",
    "\n",
    "        IOIr = MidiEncodingTransformer.get_IOIr(IOI)\n",
    "                \n",
    "        if self.encoding == 'IOIr':\n",
    "            return zip(rel_pitches, self.bin_events(IOIr))\n",
    "        \n",
    "        logIOIr = MidiEncodingTransformer.get_logIOIr(IOIr)\n",
    "                \n",
    "        if self.encoding == 'logIOIr':\n",
    "            return zip(rel_pitches, self.bin_events(logIOIr))\n",
    "    \n",
    "        raise ValueError('{} invalid encoding'.format(self.encoding))\n",
    "        \n",
    "    def bin_events(self, sequence):\n",
    "        f = lambda x: MidiEncodingTransformer.find_nearest(x, self.bins) #function to quantize x to nearest bin value\n",
    "        \n",
    "        quantized = map(f, sequence)\n",
    "        \n",
    "        #TODO: Re-evaluate this decision and potentially represent the notes as bin indices vs bin values\n",
    "        return quantized\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_IOI(note_events):\n",
    "        \"\"\"\n",
    "        Returns the Inter-Onset Interval representation of the note timing events\n",
    "        INPUT:\n",
    "        note_events - [(t_on, t_off) for note_event in note_events] (i.e. the time (frame) of each note onset and offset)\n",
    "        \"\"\"\n",
    "        on_events, off_events = note_events\n",
    "        \n",
    "        IOI = []\n",
    "        for i, t_on in enumerate(on_events[:-1]):\n",
    "            ioi = on_events[i + 1] - t_on\n",
    "            \n",
    "            #ioi cannot be negative\n",
    "            assert(ioi > 0)\n",
    "            \n",
    "            IOI.append(ioi)\n",
    "        \n",
    "        #as specified in Pardo's work, the IOI value for the final is simply the duration of the final note\n",
    "        IOI.append(off_events[-1] - on_events[-1])\n",
    "        \n",
    "        return IOI\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_IOIr(IOI):\n",
    "        \"\"\"Returns the IOI ratio representation, given a IOI represenation\"\"\"\n",
    "        IOIr = []\n",
    "        for i, ioi in enumerate(IOI[:-1]):\n",
    "            ioir = IOI[i + 1] / ioi\n",
    "            IOIr.append(ioir)\n",
    "        \n",
    "        return IOIr\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_logIOIr(IOIr):\n",
    "        \"\"\"Returns the log IOI ratio representation, given an IOIr representation\"\"\"\n",
    "        import numpy as np\n",
    "        return np.log2(IOIr)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def find_nearest(value, array):\n",
    "        \"\"\"\n",
    "        Returns the `x` in `array` that is nearest to `value`\n",
    "        From: http://stackoverflow.com/questions/2566412/find-nearest-value-in-numpy-array\n",
    "        \"\"\"\n",
    "        idx = np.searchsorted(array, value, side=\"left\")\n",
    "        \n",
    "        #case where value is larger than anything in array\n",
    "        if idx == len(array):\n",
    "            return array[-1]\n",
    "        \n",
    "        if math.fabs(value - array[idx-1]) < math.fabs(value - array[idx]):\n",
    "            return array[idx-1]\n",
    "        else:\n",
    "            return array[idx]\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_relative_pitches(pitches):\n",
    "        \"\"\"Given a list of absolute pitches, returns the relative pitche changes\"\"\"\n",
    "        rel_pitches = []\n",
    "        for i, p in enumerate(pitches[:-1]):\n",
    "            rel_pitches.append(pitches[i + 1] - p)\n",
    "            \n",
    "        return rel_pitches\n",
    "    \n",
    "onsets = [0, 1, 1.5, 2]\n",
    "offsets = [0.25, 1.25, 1.75, 3] \n",
    "pitches = [67, 69, 71, 67]\n",
    "\n",
    "note_events = zip(pitches, onsets, offsets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(A, B, i, j, memo):\n",
    "    if i == len(A) or j == len(B):\n",
    "        return 0\n",
    "    \n",
    "    if (i, j) in memo:\n",
    "        return memo[(i, j)]\n",
    "        \n",
    "    if A[i] == B[j]:\n",
    "        memo[(i, j)] = 1 + f(A, B, i + 1, j + 1, memo)\n",
    "    else:\n",
    "        memo[(i, j)] = max(f(A, B, i + 1, j, memo), f(A, B, i, j + 1, memo))\n",
    "        \n",
    "    return memo[(i, j)]\n",
    "\n",
    "\n",
    "def LCS(A, B):\n",
    "    return f(A, B, 0, 0, {})\n",
    "\n",
    "def modified_LCS(A, B):\n",
    "    \"\"\"\n",
    "    Penalizes for sequences that are too long to eliminate bias toward too-long sequences\n",
    "    \n",
    "    INPUT:\n",
    "    A - target sequence\n",
    "    B - predicted sequence\n",
    "    \n",
    "    OUTPUT:\n",
    "    (LCS(A, B) - ||A| - |B||)/|A|\n",
    "    \"\"\"\n",
    "    return (LCS(A, B) - abs(len(A) - len(B))) / float(len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_note_events(midi_obj):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    python-midi object\n",
    "    \n",
    "    OUTPUT:\n",
    "    [(note, on_tick, off_tick) for note in notes]\n",
    "    \"\"\"\n",
    "    import midi\n",
    "    from operator import itemgetter\n",
    "    \n",
    "    #we want absolute on and off tick\n",
    "    midi_obj.make_ticks_abs()\n",
    "    \n",
    "    #we need to match each NoteOnEvent with the note off event\n",
    "    active_notes = {} #maps pitch to t_on\n",
    "\n",
    "    event_set = set() #note, t_on, t_off\n",
    "    \n",
    "    is_on_note = lambda x: type(x) is midi.NoteOnEvent\n",
    "    is_off_note = lambda x: type(x) is midi.NoteOffEvent\n",
    "    \n",
    "    for track in midi_obj:\n",
    "        for event in track:\n",
    "            if is_on_note(event):\n",
    "                assert event.get_pitch() not in active_notes\n",
    "                active_notes[event.get_pitch()] = event.tick\n",
    "            elif is_off_note(event):\n",
    "                assert event.get_pitch() in active_notes\n",
    "                t_on = active_notes[event.get_pitch()]\n",
    "                t_off = event.tick\n",
    "                new_note_event = (event.get_pitch(), t_on, t_off)\n",
    "                event_set.add(new_note_event)\n",
    "                \n",
    "                del active_notes[event.get_pitch()]\n",
    "                \n",
    "    note_events = list(event_set)\n",
    "    \n",
    "    #sorting on start time (i.e. the value at index 1)\n",
    "    note_events.sort(key=itemgetter(1))\n",
    "    \n",
    "    return note_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import midi, utils\n",
    "\n",
    "TRUE_MIDI_PATH = 'monophonic_mp3/true_midi/harry_potter.mid'\n",
    "MP3_PATH = 'monophonic_mp3/no_noise/harry_potter.mp3'\n",
    "\n",
    "true_midi_pattern = midi.read_midifile(TRUE_MIDI_PATH)\n",
    "true_note_events = get_note_events(true_midi_pattern)\n",
    "m = MidiEncodingTransformer()\n",
    "true_encoded_sequence = m.transform(true_note_events)\n",
    "\n",
    "\n",
    "pred_midi_pattern = utils.get_midi_obj(MP3_PATH)\n",
    "pred_note_events = get_note_events(pred_midi_pattern)\n",
    "pred_encoded_sequence = m.transform(pred_note_events)\n",
    "\n",
    "print LCS(pred_encoded_sequence, true_encoded_sequence) / float(len(true_note_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pred_encoded_sequence\n",
    "print\n",
    "print true_encoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_params(true_note_events, query_filepath, transcription_params, encoding_params):\n",
    "    pred_note_events = utils.get_midi_obj(query_filepath, **transcription_params)\n",
    "    \n",
    "    m = MidiEncodingTransformer(*encoding_params)\n",
    "    true_encoding = m.transform(true_note_events)\n",
    "    pred_encoding = m.transform(pred_note_events)\n",
    "    \n",
    "    \n",
    "    return (modified_LCS(true_encoded_sequence, pred_encoding))\n",
    "\n",
    "%debug\n",
    "true_midi_pattern = midi.read_midifile(TRUE_MIDI_PATH)\n",
    "true_note_events = get_note_events(true_midi_pattern)\n",
    "\n",
    "score_params(true_note_events, MP3_PATH, {}, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import ParameterSampler\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "params = {\n",
    "    't' : np.linspace(0.01, 0.9, 5), #onset probability threshold\n",
    "    'l' : np.linspace(0.2, 0.9, 6), #pitch confidence threshold\n",
    "    's' : np.linspace(-90, -20, 5), #silence threshold, in dB\n",
    "    'pitch' : ['default', 'yin', 'yinfft', 'specacf', 'mcomb'], #method of pitch extraction\n",
    "    'onset' : ['default', 'energy', 'hfc', 'specflux', 'mkl', 'phase'] #method of onset detection\n",
    "}\n",
    "\n",
    "score_map = {}\n",
    "param_list = list(ParameterSampler(params, n_iter=3))\n",
    "\n",
    "%time scores = Parallel(n_jobs=-1)(delayed(score_params)(p) for p in param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
